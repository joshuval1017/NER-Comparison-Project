{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPKPaCPH2+6+qsNsY5r293s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NAAjktZpbZnM","executionInfo":{"status":"ok","timestamp":1722776419651,"user_tz":-330,"elapsed":481,"user":{"displayName":"joshuval james","userId":"14169466447174323533"}},"outputId":"8c61ab97-6c2c-485a-ccc7-5397fdb99129"},"outputs":[{"output_type":"stream","name":"stdout","text":["When a 15-year-old girl I see in psychotherapy ended up in the ER with second-degree burns, she was embarrassed to tell me why. Eventually she disclosed having crouched over boiling herb-infused wateâ€¦ [+132 chars]\n"]}],"source":["import requests\n","\n","# Replace 'YOUR_NEWSAPI_KEY' with your actual NewsAPI key\n","API_KEY = '2cdf367c35934e4aab87b8e1e9e33165'\n","url = f'https://newsapi.org/v2/top-headlines?country=us&apiKey={API_KEY}'\n","\n","response = requests.get(url)\n","news_data = response.json()\n","\n","# Extract the first article's content\n","article_content = news_data['articles'][0]['content']\n","print(article_content)\n"]},{"cell_type":"code","source":["import nltk\n","from nltk import word_tokenize, pos_tag, ne_chunk\n","\n","nltk.download('punkt')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","\n","# Tokenize and POS tag the article content\n","tokens = word_tokenize(article_content)\n","pos_tags = pos_tag(tokens)\n","\n","# Perform named entity recognition\n","named_entities_nltk = ne_chunk(pos_tags)\n","\n","# Extract and print named entities\n","entities_nltk = []\n","for subtree in named_entities_nltk:\n","    if isinstance(subtree, nltk.Tree):\n","        entity = \" \".join([token for token, pos in subtree.leaves()])\n","        entities_nltk.append((entity, subtree.label()))\n","\n","print(\"Entities extracted by NLTK:\")\n","for entity in entities_nltk:\n","    print(entity)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a51cHRR3eW81","executionInfo":{"status":"ok","timestamp":1722776387969,"user_tz":-330,"elapsed":524,"user":{"displayName":"joshuval james","userId":"14169466447174323533"}},"outputId":"550a9102-3c73-4817-aeaa-8a145cbd1f00"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Entities extracted by NLTK:\n","('ER', 'ORGANIZATION')\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]}]},{"cell_type":"code","source":["import spacy\n","\n","# Load SpaCy's pre-trained model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Process the article content\n","doc = nlp(article_content)\n","\n","# Extract and print named entities\n","entities_spacy = [(ent.text, ent.label_) for ent in doc.ents]\n","\n","print(\"Entities extracted by SpaCy:\")\n","for entity in entities_spacy:\n","    print(entity)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sq78UNXBeY6-","executionInfo":{"status":"ok","timestamp":1722776401347,"user_tz":-330,"elapsed":1291,"user":{"displayName":"joshuval james","userId":"14169466447174323533"}},"outputId":"f892c67c-ab27-49cc-ffd6-15e325fd5e6c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Entities extracted by SpaCy:\n","('15-year-old', 'DATE')\n","('ER', 'ORG')\n","('second', 'ORDINAL')\n"]}]},{"cell_type":"code","source":["# Compare NLTK and SpaCy entities\n","print(\"\\nComparison of NLTK and SpaCy entities:\")\n","\n","# Convert NLTK entities to a set for comparison\n","entities_nltk_set = set(entities_nltk)\n","entities_spacy_set = set(entities_spacy)\n","\n","# Find common, unique to NLTK, and unique to SpaCy entities\n","common_entities = entities_nltk_set.intersection(entities_spacy_set)\n","unique_to_nltk = entities_nltk_set.difference(entities_spacy_set)\n","unique_to_spacy = entities_spacy_set.difference(entities_nltk_set)\n","\n","print(\"\\nCommon Entities:\")\n","for entity in common_entities:\n","    print(entity)\n","\n","print(\"\\nEntities Unique to NLTK:\")\n","for entity in unique_to_nltk:\n","    print(entity)\n","\n","print(\"\\nEntities Unique to SpaCy:\")\n","for entity in unique_to_spacy:\n","    print(entity)\n","\n","# Observations\n","print(\"\\nObservations:\")\n","print(\"NLTK tends to generate more generic entities and may miss some specific entities.\")\n","print(\"SpaCy, being a machine learning-based approach, tends to identify more specific entities and can recognize a broader range of entity types.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2c4hRGiceve_","executionInfo":{"status":"ok","timestamp":1722776492108,"user_tz":-330,"elapsed":505,"user":{"displayName":"joshuval james","userId":"14169466447174323533"}},"outputId":"4e75c681-4cff-4057-ebc6-4f530130844a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Comparison of NLTK and SpaCy entities:\n","\n","Common Entities:\n","\n","Entities Unique to NLTK:\n","('ER', 'ORGANIZATION')\n","\n","Entities Unique to SpaCy:\n","('15-year-old', 'DATE')\n","('second', 'ORDINAL')\n","('ER', 'ORG')\n","\n","Observations:\n","NLTK tends to generate more generic entities and may miss some specific entities.\n","SpaCy, being a machine learning-based approach, tends to identify more specific entities and can recognize a broader range of entity types.\n"]}]}]}